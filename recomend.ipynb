{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "recomend.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dwGlfaJh_vX"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "from pandas import DataFrame\n",
        "import random\n",
        "from math import ceil\n",
        "from math import log"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGtn_lEtaQ1M"
      },
      "source": [
        "Сделаем код воспроизводимым, также, в дальнейшем, во все алгоритмы будем добавлять $seed$ как $random\\_state$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4siSQQhaCsaP"
      },
      "source": [
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg-oD4laEgIi"
      },
      "source": [
        "Загрузим данные любым способом"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmsYss5YtPei"
      },
      "source": [
        "Загрузка из гугл-диска"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aMpcYPBhZ5x",
        "outputId": "1d261377-0db1-40bf-caa1-5e87a26c60c5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path_to_files = '/content/drive/My Drive/data/'"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOHIBs5ctXXS"
      },
      "source": [
        "Загрузка из локального хранилища"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrNxhv6_tbWI"
      },
      "source": [
        "path_to_files = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KLowJAwAJfZ"
      },
      "source": [
        "Общая загрузка"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dS8eYSvphra-"
      },
      "source": [
        "movie = pd.read_csv(path_to_files + 'movie.csv')\n",
        "rating = pd.read_csv(path_to_files + 'rating.csv')\n",
        "link = pd.read_csv(path_to_files + 'link.csv')\n",
        "tag = pd.read_csv(path_to_files + 'tag.csv')\n",
        "gen_tags = pd.read_csv(path_to_files + 'genome_tags.csv')\n",
        "gen_scores = pd.read_csv(path_to_files + 'genome_scores.csv')\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBww1O-dcYY-"
      },
      "source": [
        "Изменим шкалу рейтинга, т.к в датасете она (min=0.5; max=5; step=0.5), сделав её (min=1; max=10; step=1)\n",
        "\n",
        "Также, оставим только столбцы для нашей матрицы кросс-табуляции"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cq5HFVgscmWA",
        "outputId": "74df04fb-8238-4b08-de3e-2a6a557c5652"
      },
      "source": [
        "rating['rating'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3.5, 4. , 3. , 4.5, 5. , 2. , 1. , 2.5, 0.5, 1.5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn1CtR_uiDfD"
      },
      "source": [
        "rating['rating'] = (rating['rating'] * 2).astype(int)\n",
        "rating['rating'].value_counts()\n",
        "rating = rating[rating.columns[:3]]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0306QysmJsC"
      },
      "source": [
        "Сделаем разбиение:\n",
        "\n",
        "Нам необходимо, чтобы в обучающей выборке был хотя бы один пример для каждого пользователя и каждого фильма, иначе наша модель будет невалидна, для заданной пары пользователь/фильм она не сможет выдать корректный ответ, ибо не будет иметь данных о ней. \n",
        "\n",
        "Например, в таком случае модель из $surprise$ выдаст ответ, в котором будет записано, что выдать правильный ответ было невозможно, $was \\space impossible = True$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NB2i3k-Jd1wd"
      },
      "source": [
        "Функция, которая помещает в $train$ датасет как минимум по 1 экземпляру уникальных $userId$, по 1 экземпляру уникальных $movieId$, далее заполняет случайным образом $train$ до нужного отношения $\\frac{train}{full\\_dataset}$ равное $ratio$, оставшиеся данные добавляет в $valid$ и $test$ пополам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2B2Oq8Hdq6P"
      },
      "source": [
        "def train_valid_test_split(dataset : DataFrame, ratio : float) -> tuple:\n",
        "\n",
        "    users = dataset.loc[dataset['userId'].drop_duplicates().index]\n",
        "    movies = dataset.loc[dataset['movieId'].drop_duplicates().index]\n",
        "    train = users.merge(movies, how=\"outer\")\n",
        "    test = dataset.drop(train.index) \n",
        "\n",
        "    num_to_choice = int(len(dataset) * ratio) - len(train)\n",
        "    index = np.random.choice(test.index, size=num_to_choice)\n",
        "    train = train.append(test.loc[index])\n",
        "    test = test.drop(index)\n",
        "\n",
        "    index = np.random.choice(test.index, size=int(len(test)/2))\n",
        "    valid = test.loc[index]\n",
        "    test = test.drop(index)\n",
        "\n",
        "    return train, valid, test"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2TkNq4vccNH"
      },
      "source": [
        "Разделим датасет на $train$, $valid$ и $test$. Подбор гиперпараметров будем делать на валидации, на тесте будем фиксировать итоговое качество моделей, по которым и будем их сравнивать"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMt72FRAcan8"
      },
      "source": [
        "train_set, valid_set, test_set = train_valid_test_split(rating, 0.9)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om8AjdEAamjX"
      },
      "source": [
        "Для простого коллаборативного подхода воспользуемся $surprise$ — https://surprise.readthedocs.io/en/stable/index.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-4xyYDFjN0K",
        "outputId": "914d168f-1e67-4282-981e-89a934be333e"
      },
      "source": [
        "!pip install surprise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: surprise in /usr/local/lib/python3.7/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.7/dist-packages (from surprise) (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.0.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise->surprise) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V0ylR39dA3h"
      },
      "source": [
        "from surprise import Reader\n",
        "from surprise import Dataset\n",
        "from surprise import AlgoBase\n",
        "from surprise import Reader\n",
        "from surprise import Prediction\n",
        "from surprise import NMF\n",
        "from surprise import accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wKWFnZoa-9A"
      },
      "source": [
        "Выберем метрику: \n",
        "\n",
        "Возьмём как pointwise метрику - $RMSE$, чтобы можно было оценить, насколько в среднем наш алгоритм отклоняется от правильной оценки \n",
        "\n",
        "В качества listwise метрики возьмём $NDCG$ (https://en.wikipedia.org/wiki/Discounted_cumulative_gain#Normalized_DCG), чтобы можно было оценить, насколько хорошо наш алгоритм ранжирует фильмы по оценкам для пользователя в процентах. За счёт логарифмов, каждый следующий ранг начинает вносить всё меньше и меньше значимости, т.к зачастую нам важно именно выдать top-k рекомендаций, и уже не так важно, что будет дальше"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD4_otfubqoI"
      },
      "source": [
        "В $surprise$ есть свой $RMSE$, а вот $NDCG$ необходимо будет написать самостоятельно"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKKADLT5b97k"
      },
      "source": [
        "def ndcg(predictions : list, verbose = False) -> float:\n",
        "\n",
        "    line = [[predictions[i].est, predictions[i].r_ui] for i in range(len(predictions))]\n",
        "    sl = sorted(line, key = lambda el : el[1], reverse = True)\n",
        "\n",
        "    idcg_res = np.array([(2 ** sl[i - 1][1] - 1) / log(i + 1, 2) for i in \n",
        "                         range(1, len(sl) + 1)]).sum()\n",
        "\n",
        "    sl = sorted(line, key = lambda el : el[0], reverse = True)\n",
        "    ndcg_res = np.array([(2 ** sl[i - 1][1] - 1) / log(i + 1, 2) for i in \n",
        "                         range(1, len(sl) + 1)]).sum()\n",
        "\n",
        "    metric_res = ndcg_res/idcg_res\n",
        "    if verbose:\n",
        "        print(\"NDCG: \", metric_res)\n",
        "\n",
        "    return metric_res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chyMQGad-fh9"
      },
      "source": [
        "Обучение\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6Jsxv15ciYV"
      },
      "source": [
        "Округляем ответы к ближайшему целому"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRd-DR_HliQO"
      },
      "source": [
        "def predict(model : AlgoBase,\n",
        "            data: DataFrame) -> list:\n",
        "\n",
        "    pred = model.test(data.to_numpy())\n",
        "    return [Prediction(p.uid, p.iid, p.r_ui, round(p.est), p.details) for p in pred]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXmUcDTkQaRR"
      },
      "source": [
        "def train(model : AlgoBase, \n",
        "          train_dataset : DataFrame, \n",
        "          valid_dataset : DataFrame, \n",
        "          reader : Reader,\n",
        "          metrics : dict,\n",
        "          verbose = False) -> dict:\n",
        "\n",
        "\n",
        "    if verbose: \n",
        "        print(\"Train\")\n",
        "\n",
        "    model.fit(Dataset.load_from_df(train_dataset, reader).build_full_trainset())\n",
        "\n",
        "    if verbose: \n",
        "        print(\"Valid\")\n",
        "\n",
        "    predicted = predict(model, valid_dataset)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Metrics:\")\n",
        "\n",
        "    metrics_value = {k : v(predicted, verbose=verbose) for k, v in metrics.items()}\n",
        "\n",
        "    if verbose:\n",
        "        print(metrics_value)\n",
        "\n",
        "    return metrics_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plRoqwCaexkK"
      },
      "source": [
        "В качесте модели возьмём NMF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-tvvPxRmiux"
      },
      "source": [
        "reader = Reader(rating_scale=(1, 10))\n",
        "metrics = {\"RMSE\" : accuracy.rmse, \"NDCG\" : ndcg}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6izNZ2wDKoj"
      },
      "source": [
        "model_nmf = NMF(n_factors = 30, random_state=seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YSwHn83ChE-_",
        "outputId": "b8592450-8727-4501-de03-aca3da8ebe3f"
      },
      "source": [
        "metrics_value = train(model_nmf, train_set, valid_set, reader, metrics, verbose = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "Valid\n",
            "Metrics:\n",
            "RMSE: 1.7854\n",
            "NDCG:  0.9592456471378288\n",
            "{'RMSE': 1.7854111921626319, 'NDCG': 0.9592456471378288}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlbzgKYZeeYm"
      },
      "source": [
        "Попробуем улучшить результаты, сделав кросс-валидацию по некоторым важным параметрам, которые влияют на сходимость и качество модели\n",
        "\n",
        "Отбирать лучшую модель будем по $NDCG$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjwUYYK7-XMH"
      },
      "source": [
        "param_grid = {'n_factors' : [15, 30, 50],\n",
        "              'reg_pu' : [0.04, 0.06, 0.08],\n",
        "              'reg_qi' : [0.04, 0.06, 0.08]\n",
        "              }\n",
        "\n",
        "best_ndcg = 0\n",
        "best_params = {'n_factors' : 0, 'reg_pu' : 0, 'reg_qi' : 0}\n",
        "\n",
        "for reg_pu in param_grid['reg_pu']:\n",
        "\n",
        "    for reg_qi in param_grid['reg_qi']: \n",
        "\n",
        "        for n_factor in param_grid['n_factors']:\n",
        "\n",
        "            model = NMF(n_factors=n_factor, random_state=seed,\n",
        "                        reg_qi=reg_qi, reg_pu=reg_pu)\n",
        "            \n",
        "            metrics_value = train(model, train_set, valid_set, reader, metrics, verbose=True)\n",
        "            \n",
        "            print(\"num factors = \", n_factor)\n",
        "            print(\"users regularization = \", reg_pu) \n",
        "            print(\"items regularization = \", reg_qi)\n",
        "\n",
        "            print(\"Metrics:\")\n",
        "            print(metrics_value)\n",
        "            print(\"\\n\")\n",
        "            if (metrics_value['NDCG'] > best_ndcg):\n",
        "\n",
        "                best_ndcg = metrics_value['NDCG']\n",
        "                best_params['n_factors'] = n_factor\n",
        "                best_params['reg_pu'] = reg_pu\n",
        "                best_params['reg_qi'] = reg_qi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMmmeeoh9vz0"
      },
      "source": [
        "print(\"Best params: \")\n",
        "print(best_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg5PCThG_Fn3",
        "outputId": "543445c0-5291-49b4-f29d-29f3d117e802"
      },
      "source": [
        "model = NMF(n_factors=30, random_state=seed,\n",
        "                        reg_qi=0.06, reg_pu=0.06)\n",
        "            \n",
        "train(model, train_set, valid_set, reader, metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'NDCG': 0.9592456471378288, 'RMSE': 1.7854111921626319}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXHcis_FSfvo"
      },
      "source": [
        "Протестируем модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSmlZ1mw_cey",
        "outputId": "b11bee6d-f637-4cd1-a951-f202a50bf840"
      },
      "source": [
        "pred = predict(model, test_set)   \n",
        "ndcg(pred, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NDCG:  0.9598020553583039\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9598020553583039"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C4h2TbkCoqA"
      },
      "source": [
        "$NDCG = 0.9598$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h7ZAqPCaQ4W"
      },
      "source": [
        "Попробуем не только коллаборативный, но также и контекстный подход\n",
        "\n",
        "Эту задачу будем решать с помощью $LightFM$ — https://making.lyst.com/lightfm/docs/home.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsjlj56obbZB",
        "outputId": "cfbad8d7-ac62-46b0-df14-f759dd961d0a"
      },
      "source": [
        "!pip install lightfm"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lightfm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/fe/8864d723daa8e5afc74080ce510c30f7ad52facf6a157d4b42dec83dfab4/lightfm-1.16.tar.gz (310kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from lightfm) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from lightfm) (2.23.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightfm) (0.22.2.post1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->lightfm) (2020.12.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightfm) (1.0.1)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.16-cp37-cp37m-linux_x86_64.whl size=705341 sha256=6b2e96d3fa21e2abd9a2088213264c6771da6e55d4da66dd61b64026c2c98c11\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/64/d4/673c7277f71ac4c5ad4835b94708c01b653ef2d3aa78ef20aa\n",
            "Successfully built lightfm\n",
            "Installing collected packages: lightfm\n",
            "Successfully installed lightfm-1.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6LVpyimbSyr"
      },
      "source": [
        "from lightfm import LightFM\n",
        "from scipy.sparse.coo import coo_matrix"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tIrYbZLc-lG"
      },
      "source": [
        "def cross_tabulation_to_sparse(dataset : DataFrame) -> coo_matrix:\n",
        "\n",
        "    row = dataset['userId'].to_numpy(dtype='int')\n",
        "    col = dataset['movieId'].to_numpy(dtype='int')\n",
        "    data = dataset['rating'].to_numpy(dtype='int')\n",
        "\n",
        "    return coo_matrix((data, (row, col)))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pp0x_smEnvor"
      },
      "source": [
        "Для контекстного подхода, кроме матрицы кросс-табуляции нам также требуются и какие-то признаки об объектах и пользователях"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWc3Ldqj_Dnc"
      },
      "source": [
        "Из информации о фильмах будем брать год фильма, а также One-hot-encoding представление жанров"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "tGOpld4YnN1t",
        "outputId": "5b60aac4-40a1-4d1c-86e1-b4e8900ce640"
      },
      "source": [
        "movie.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movieId  ...                                       genres\n",
              "0        1  ...  Adventure|Animation|Children|Comedy|Fantasy\n",
              "1        2  ...                   Adventure|Children|Fantasy\n",
              "2        3  ...                               Comedy|Romance\n",
              "3        4  ...                         Comedy|Drama|Romance\n",
              "4        5  ...                                       Comedy\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kodWXZCy-d2g"
      },
      "source": [
        "Будем собирать информацию о фильмах"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dhdrz8wz7BVA"
      },
      "source": [
        "movie_info = rating.merge(movie, how=\"left\", on=\"movieId\")[['movieId', 'title', 'genres']]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIJLpmPo-hIX"
      },
      "source": [
        "Добавм информацию о годе выпуска фильма (0 - если не указано)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDkHHIcxvrT7"
      },
      "source": [
        "import re\n",
        "movie_info['Year'] = movie_info['title'].apply(lambda s: (['0'] + re.findall(\"(\\d{4})\", s))[-1]).astype('int')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkq3IUeq-oAd"
      },
      "source": [
        "Получим множество всех жанров"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3gqvZlo383n"
      },
      "source": [
        "genres = set()\n",
        "for l_g in movie_info['genres'].unique():\n",
        "\n",
        "    for genre in l_g.split('|'):\n",
        "        genres.add(genre)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50wJQAc0-tnx"
      },
      "source": [
        "Сделаем one-hot-encoding кодирование жанров фильмов, добавив каждому фильму 1 в соответствующий столбец с жанром, если этот фильм принадлежит данному жанру, иначе 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8IC6Z8reLrx"
      },
      "source": [
        "Полученные матрицы будут огромны, порядка $16 * 10^6 * 21$ из-за one-hot-encoding'а, поэтому все действия нужно делать очень аккуратно, лишнее копирование и получим переполнение ОЗУ. И конечно же, все операции будут выполняться с разреженными матрицами"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnDl-wxDe0rJ"
      },
      "source": [
        "Разделим информацию о фильмах"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo-JsBCUji6e"
      },
      "source": [
        "train_movie_info = movie_info.loc[train_set.index]\n",
        "valid_movie_info = movie_info.loc[valid_set.index]\n",
        "test_movie_info = movie_info.loc[test_set.index]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BONoAn6He3P1"
      },
      "source": [
        "Удалим индексы фильмов, т.к матрица по одной из размерностей будет совпадать с матрицей кросс-табуляции, в которой содержится информация об этом"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqviyvPHo2Ap"
      },
      "source": [
        "train_movie_info.drop(columns=\"movieId\", inplace=True)\n",
        "valid_movie_info.drop(columns=\"movieId\", inplace=True)\n",
        "test_movie_info.drop(columns=\"movieId\", inplace=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om5BEs4Bj2At"
      },
      "source": [
        "train_ohe_movie = pd.DataFrame()\n",
        "valid_ohe_movie = pd.DataFrame()\n",
        "test_ohe_movie = pd.DataFrame()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AM2SP6Fj_ii"
      },
      "source": [
        "train_ohe_movie['Year'] = train_movie_info['Year']\n",
        "valid_ohe_movie['Year'] = valid_movie_info['Year']\n",
        "test_ohe_movie['Year'] = test_movie_info['Year']"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWdL2HkqfEV5"
      },
      "source": [
        "Делаем one-hot-encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTbKHsIPwi4t",
        "outputId": "09771018-fc10-4f5a-f6d6-8871b057207c"
      },
      "source": [
        "for genre in genres:\n",
        "\n",
        "    train_ohe_movie[genre] = train_movie_info['genres'].apply(lambda s: int(bool(s.find(genre) + 1)))\n",
        "    valid_ohe_movie[genre] = valid_movie_info['genres'].apply(lambda s: int(bool(s.find(genre) + 1)))\n",
        "    test_ohe_movie[genre] = test_movie_info['genres'].apply(lambda s: int(bool(s.find(genre) + 1)))\n",
        "    print(genre, \" was added in data\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Children  was added in data\n",
            "Documentary  was added in data\n",
            "Comedy  was added in data\n",
            "Film-Noir  was added in data\n",
            "Sci-Fi  was added in data\n",
            "Drama  was added in data\n",
            "Mystery  was added in data\n",
            "(no genres listed)  was added in data\n",
            "Romance  was added in data\n",
            "IMAX  was added in data\n",
            "Musical  was added in data\n",
            "Animation  was added in data\n",
            "Fantasy  was added in data\n",
            "Western  was added in data\n",
            "Action  was added in data\n",
            "Crime  was added in data\n",
            "Horror  was added in data\n",
            "Thriller  was added in data\n",
            "War  was added in data\n",
            "Adventure  was added in data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g9pPbaT_PPy"
      },
      "source": [
        "Можно брать оценки и популярность фильма из omdbapi, или tmdb, но они оба ставят ограничения на free api, поэтому разметить наш датасет (20M) не получится, но в теории возможно"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "2yxub56poxnB",
        "outputId": "9ac0704f-1be4-4c90-f2d0-a88de4bf056d"
      },
      "source": [
        "link.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>imdbId</th>\n",
              "      <th>tmdbId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>114709</td>\n",
              "      <td>862.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>113497</td>\n",
              "      <td>8844.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>113228</td>\n",
              "      <td>15602.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>114885</td>\n",
              "      <td>31357.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>113041</td>\n",
              "      <td>11862.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   movieId  imdbId   tmdbId\n",
              "0        1  114709    862.0\n",
              "1        2  113497   8844.0\n",
              "2        3  113228  15602.0\n",
              "3        4  114885  31357.0\n",
              "4        5  113041  11862.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1j32ceAW_qwj"
      },
      "source": [
        "Данная информация содержит слишком разные теги, хотя вообще, можно получать какой-то эмбеддинг из текстового тега и добавлять к нашей информации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "MDSDegxWr142",
        "outputId": "4daf9bce-f9f1-404e-e8b3-51a0a392b72a"
      },
      "source": [
        "tag.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>tag</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18</td>\n",
              "      <td>4141</td>\n",
              "      <td>Mark Waters</td>\n",
              "      <td>2009-04-24 18:19:40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>65</td>\n",
              "      <td>208</td>\n",
              "      <td>dark hero</td>\n",
              "      <td>2013-05-10 01:41:18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65</td>\n",
              "      <td>353</td>\n",
              "      <td>dark hero</td>\n",
              "      <td>2013-05-10 01:41:19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>65</td>\n",
              "      <td>521</td>\n",
              "      <td>noir thriller</td>\n",
              "      <td>2013-05-10 01:39:43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65</td>\n",
              "      <td>592</td>\n",
              "      <td>dark hero</td>\n",
              "      <td>2013-05-10 01:41:18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId            tag            timestamp\n",
              "0      18     4141    Mark Waters  2009-04-24 18:19:40\n",
              "1      65      208      dark hero  2013-05-10 01:41:18\n",
              "2      65      353      dark hero  2013-05-10 01:41:19\n",
              "3      65      521  noir thriller  2013-05-10 01:39:43\n",
              "4      65      592      dark hero  2013-05-10 01:41:18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrZFSaRrADFZ"
      },
      "source": [
        "Сделаем все матрицы разреженными"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNsd-IOBS9GF"
      },
      "source": [
        "train_movie_info = (train_ohe_movie.astype(pd.SparseDtype(int, fill_value=0))).sparse.to_coo()\n",
        "valid_movie_info = (valid_ohe_movie.astype(pd.SparseDtype(int, fill_value=0))).sparse.to_coo()\n",
        "test_movie_info = (test_ohe_movie.astype(pd.SparseDtype(int, fill_value=0))).sparse.to_coo()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnY8IzopOMo1"
      },
      "source": [
        "train_set_coo = cross_tabulation_to_sparse(train_set)\n",
        "valid_set_coo = cross_tabulation_to_sparse(valid_set)\n",
        "test_set_coo = cross_tabulation_to_sparse(test_set)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmeuPb1zfaJ-"
      },
      "source": [
        "Обучение и подбор модели\n",
        "\n",
        "Из-за огромных размеров датасета, делать кросс-валидацию в ноутбуке сложно, лучшие гиперпараметры подбирались итеративно по $NDCG$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ9Oid4JPvLd"
      },
      "source": [
        "model = LightFM(loss='warp', no_components = 30, learning_rate = 0.01, random_state=seed)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAhKg6M9O-Ug",
        "outputId": "5bbf6699-6ff8-40c6-b39b-949b439e6ef6"
      },
      "source": [
        "model.fit(train_set_coo,\n",
        "          user_features=train_movie_info,\n",
        "          epochs=80,\n",
        "          verbose=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|██████████| 80/80 [1:25:54<00:00, 64.43s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7f9d06eb0e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_3GaqnbcNoc"
      },
      "source": [
        "predictions = model.predict(valid_set['userId'].to_numpy(),\n",
        "                            valid_set['movieId'].to_numpy(),\n",
        "                            user_features=valid_movie_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tbU__MUfvD6"
      },
      "source": [
        "Немного поменяем метрику $NDCG$ под эту библиотеку"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOSXxYtq_FC0"
      },
      "source": [
        "def ndcg_lightfm(predictions : np.array, y_true : np.array , verbose = False) -> float:\n",
        "\n",
        "    line = [[predictions[i], y_true[i]] for i in range(len(predictions))]\n",
        "    \n",
        "    sl = sorted(line, key = lambda el : el[1], reverse = True)\n",
        "    idcg_res = np.array([(2 ** sl[i - 1][1] - 1) / log(i + 1, 2) for i in \n",
        "                         range(1, len(sl) + 1)]).sum()\n",
        "\n",
        "    sl = sorted(line, key = lambda el : el[0], reverse = True)\n",
        "    ndcg_res = np.array([(2 ** sl[i - 1][1] - 1) / log(i + 1, 2) for i in \n",
        "                         range(1, len(sl) + 1)]).sum()\n",
        "\n",
        "    metric_res = ndcg_res/idcg_res\n",
        "    if verbose:\n",
        "        print(\"NDCG: \", metric_res)\n",
        "\n",
        "    return metric_res"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D670G6CMf2WN"
      },
      "source": [
        "Заметим, что $LightFM$ выдаёт только список рангов в другом пространстве, а не значения рейтингов, как в нашем датасете, поэтому её нельзя тестировать на $RMSE$, чтобы оценить модель интуитивно - на отклонение оценок от оптимального"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llSlygIocTIa"
      },
      "source": [
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoI2LarRcUnc"
      },
      "source": [
        "ndcg_lightfm(predictions, valid_set['rating'].to_numpy(),verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acCvzBNlN-yj"
      },
      "source": [
        "Протестируем нашу модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7-EsQErN6ww"
      },
      "source": [
        "predictions = model.predict(test_set['userId'].to_numpy(),\n",
        "                            test_set['movieId'].to_numpy(),\n",
        "                            user_features=test_movie_info)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6ulprAaPz5t",
        "outputId": "bab501e0-788a-44fd-c21d-873a7d65ec76"
      },
      "source": [
        "ndcg_lightfm(predictions, test_set['rating'].to_numpy(),verbose=True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NDCG:  0.9266153695432057\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9266153695432057"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYGWDJdOCyLn"
      },
      "source": [
        "$NDCG = 0.9266$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1XhkdRMhX_f"
      },
      "source": [
        "По метрике $NDCG$, можно сказать, что простая коллаборативная модель ранжирует лучше, чем та, которая кроме этого использует контекст.\n",
        "Возможные причины этого: \n",
        "\n",
        "1.   Возможно, модель лучше покажет себя на какой-то другой метрике, которую она конкретно оптимизирует, например для $warp$ лосса, который мы использовали во второй модели, больше подходит $precision@k$\n",
        "2.   Плохой подбор параметров\n",
        "3.   Недостаточное количество эпох для обучения\n",
        "4.   Плохой выбор пространства признаков (One-hot-encoding жанров) для данных условий, из-за чего модель сложно (большой размер данных с ограниченным ОЗУ, порядка $16 * 10^6 * 21$ значений) и долго обучать, то есть эта причина влечёт за собой вторую и третью\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELfXaWnbE7Xx"
      },
      "source": [
        "Проверим статистическую значимость результатов на $NMF$ модели на уровне значимости $p_{value} = 0.05$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lONdksWPGl1K"
      },
      "source": [
        "Гипотеза $H_0$: распределения предсказаний и настоящих рейтингов не отличаются\n",
        "\n",
        "Гипотеза $H_1$: распределения предсказаний и настоящих рейтингов отличаются"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INbKnvtWF5oi",
        "outputId": "199b6351-f497-47a6-aff1-cc476bd30bc4"
      },
      "source": [
        "train(model_nmf, train_set, valid_set, reader, metrics, True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "Valid\n",
            "Metrics:\n",
            "RMSE: 1.7854\n",
            "NDCG:  0.9592456471378288\n",
            "{'RMSE': 1.7854111921626319, 'NDCG': 0.9592456471378288}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'NDCG': 0.9592456471378288, 'RMSE': 1.7854111921626319}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytI1V0HH74_G"
      },
      "source": [
        "from scipy.stats import chisquare\n",
        "\n",
        "def stat_test(pred : Prediction):\n",
        "\n",
        "    f_exp_obs = np.array([[p.est, p.r_ui] for p in pred])\n",
        "    return chisquare(f_exp = f_exp_obs[:, 1], f_obs = f_exp_obs[:, 0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILa5xywyEtY4"
      },
      "source": [
        "pred = predict(model_nmf, test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vx2Doub-HKsI"
      },
      "source": [
        "test_value = stat_test(pred)\n",
        "p_value = 0.05"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTgoHgLsFZCX",
        "outputId": "ecae3ec7-1ab1-485e-b6db-ab2b94b7aee1"
      },
      "source": [
        "if test_value.pvalue > p_value:\n",
        "    print(\"Нельзя отвергнуть гипотезу H_0\")\n",
        "else:\n",
        "    print(\"Гипотеза H_0 отвергается, принимается гипотеза H_1\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Нельзя отвергнуть гипотезу H_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHpfag_gjQib"
      },
      "source": [
        "Выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH-Jj_98jpJ1"
      },
      "source": [
        "\n",
        "1.   От метрики очень сильно зависит отбор кандидатов моделей, нужно внимательно проанализировать, что мы хотим получать от модели в результате, и уже от этого выбирать метрику\n",
        "2.   Даже простая модель может выдавать неплохие результаты\n",
        "3.   Сложные модели требуют тщательной настройки гиперпараметров\n",
        "4.   Сложные модели тяжело обучать, потому что у них больше пространство признаков $=>$ требуется больше времени для обучения и больше памяти для данных\n",
        "5.   Из всего выше, следует, что самый оптимальный вариант для рекомендательной системы — обучать простую модель, которая будет выбирать $top-k$ лучших кандидатов, и их подавать в более тяжеловесную модель с большим количеством признаков, которая будет более точно ранжировать этот список\n",
        "\n"
      ]
    }
  ]
}